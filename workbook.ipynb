{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook \n",
    "This is a blank jupiter notebook file for you to work on with a new dataset and try out some of the things that have being showen throughout the first 4 notebooks. \n",
    "Why not try:\n",
    "* Importing dataset\n",
    "* Cleaning dataset\n",
    "* Making surface level stats on some of the columns (mean,median,mode) - in a table \n",
    "* Create some graphs and charts that are relevent about the data\n",
    "* Try converting continuous data to categorical\n",
    "* Create some continceny tables \n",
    "\n",
    "\n",
    "This is a jupiter notebook file for you to work, at the end of the FutureMe week you will then export this workbook and upload it so that you can get your RISE points for this course. \n",
    "The notebook is going to go over the code that you have seen from each of the days notebook, to give you some examples of what you might be doing when analysiing data. \n",
    "\n",
    "When it comes to data in this notebook - you can try and work with any of the databases in the Data folder. I would recommend using the a different dataset to the titanic dataset for the days 2-4 workbook, since you want to be able to analyse different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start running any of the code we need to import all our modules \n",
    "# Run this cell at the beginning before you run any of the other cells\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day One: Introduction to Python and Python for Data Analysis\n",
    "Aims for this days workbook:\n",
    "- Work through the basic python problems \n",
    "- Running basic data methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2650658987.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/3t/bfly_r6n5m51xp78vkb5tk_40000gn/T/ipykernel_80396/2650658987.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x =\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Try running this cell. What's wrong with it ? \n",
    "# Can you try fix the code so that the code will print a number \n",
    "x \n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data type\n",
    "\n",
    "# What data type would you store you name in ?\n",
    "name = \n",
    "\n",
    "# What data type would you store your age ? \n",
    "\n",
    "age = \n",
    "\n",
    "# What data type would you store a grade between 1 and 0 \n",
    "average_score = \n",
    "\n",
    "# What could you do to store whether you taking a placement year\n",
    "placement_year = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try storing the above variables \n",
    "student_record = {\n",
    "    'name':\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are finding this easy so far, why not try using a list inside the dictionary to add more student data to the student_record discitonary\n",
    "full_student_record = {\n",
    "    'name':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The titanic data has being imported and stored in the variable titanic \n",
    "\n",
    "# Connected to internet\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/chroadhouse/FutureMeWorkbook/main/Data/titanic.csv')\n",
    "\n",
    "# If you are running localy on your machine\n",
    "\n",
    "# Try running the method that we use to test that the data set has being imported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running the code to find the name of the columns on the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running the code to find the count of how many NaN's there are and what the data types are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a method to create a table of all the stats for the quantitative columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day Two: Understanding and Visualising Data\n",
    "Aims for this section\n",
    "- Create your own table of stats for a quantitative column of the dataset you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import you data set \n",
    "\n",
    "# Put a file path or link to raw github webpage\n",
    "data = pd.read_csv()\n",
    "\n",
    "# Make sure that youre data is loaded\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variales for mean, median, mode, max, min and standard deviation for a column\n",
    "# Then create a table to store these varaibles \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table that stores the value counts of categorical data\n",
    "# You can also try adding a second column that had the percentages -- Look at the Day Two Notebook for a hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Histogram on some quantitative column, remeber to label the x and y axis and give it a title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pie Chart for some quantitative data and add the percenatges onto it\n",
    "# Don't forget labels and a title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bar Chart with some qualitative data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day Three: Cleaning data\n",
    "Aims for this section \n",
    "- Clean the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to import a different dataset do it here and store it as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by finding out how many values are missing in each column running a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Cleaning the data some ideas:\n",
    "# - Get the mean of quantitative data and replace the NaN\n",
    "# - Get the most frequent value for the value count and replace the NaN for categorical columns\n",
    "# - Drop any columns that are mising a lot of data \n",
    "\n",
    "# Run the method to check value NaN's at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day Four: Contingency Tables \n",
    "Recommend using the data set that you cleaned in the previous section for Day Three\n",
    "The aim of this section is to create some contingency tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table between two categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have been working with the same data set over a few days why not try and write down three findings and conclusions you can find:\n",
    "    To do this double click this markdown and then write your answer. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to save and upload \n",
    "This will be changed at a further date\n",
    "\n",
    "### How to save the workbook as a pdf:\n",
    "This will work for both PC and Mac as long as you are using Google Collab. \n",
    "If you are using Google Collab:\n",
    "- Go to file\n",
    "- Scroll down and press print\n",
    "- When the pop up shows, go onto the printer and select save a pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Future\n",
    "Well done on getting through the FutureMe week for this course. Programming and data analysis are great skills to have and are sought after in jobs. \n",
    "\n",
    "If you have enjoyed this brief introduction to Python for data analysis, you should consider broadening your knowledge on the subject. In a society that is placing more and more emphasis on digital skills, Python in particular is a brilliantly versatile one to have on your CV, showing:\n",
    "   * Your ability to solve problems\n",
    "   * Digital fluency\n",
    "   * Your motivation to learn\n",
    "\n",
    "Programming and computer science is one of the main subjects that has a large number of detailed resources to help you learn and develop. Some of these resources even provide certificates as proof of your capability in programming.\n",
    "* FreeCodeCamp -  https://www.freecodecamp.org - Provides easy and intuative courses with certificates to give credit for course completion offering courses such as:\n",
    "    - Web development\n",
    "    - Data Analysis using python \n",
    "    - Scientific computing using python \n",
    "    - Machine Learning (AI) using python \n",
    "    - Algorithms and Data structures in Javascript \n",
    "\n",
    "* Linkedin Learning - All MMU students have free access to LinkedIn Learning. It provides video courses and certificates linked to your LinkedIn account (this also automatically earns you Rise points too)!\n",
    "\n",
    "* CS Dojo - Videos on Youtube that provide multiple resources aimed at beginners to try and encourage coding.\n",
    "\n",
    "* Rise - It's also a good idea to keep an eye on the Rise website, as new courses are being added all the time. Currently, you can sign up for Python for Scientific Computing and TensorFlow for Artificial Intelligence with Stephen Lynch: https://rise.mmu.ac.uk/activity/python-for-scientific-computing-and-tensorflow-for-artificial-intelligence-3/\n",
    "\n",
    "* Or you could also preorder Stephen Lynch's book, which is centered around Python for Artificial Intelligence and Scientific Computing: https://www.routledge.com/Python-for-Scientific-Computing-and-Artificial-Intelligence/Lynch/p/book/9781032258713#\n",
    "\n",
    "\n",
    "\n",
    "And remember that even people that study Computer Science can be stuck, it's what can make programming such a rewarding skill. If you do get stuck think about:\n",
    "- Asking a friend for help\n",
    "- Looking for an answer on the internet (programmers are people that are just good at googling)\n",
    "- Leave and come back to it (You can sometimes be staring at the bug without knowing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
